{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1IrJBM4nVDxGkWNn9410cgUgQtVUe4b94",
      "authorship_tag": "ABX9TyMKTWcvUTg61P6j9Q+Gw1Xt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isaak-C-Augustus/Dark-Academia-Portfolio/blob/main/cooles_image_ML_ding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Colk7qO8vbVt"
      },
      "outputs": [],
      "source": [
        "!git remote add origin https://github.com/Isaak-C-Augustus/cool_ahhhhhh_ML_image_learning_effect.git\n",
        "!git branch -M main\n",
        "!git push -u origin main\n",
        "\n",
        "!echo \"# cool_ahhhhhh_ML_image_learning_effect\" >> README.md\n",
        "!git init\n",
        "!git add README.md\n",
        "!git commit -m \"first commit\"\n",
        "!git branch -M main\n",
        "!git remote add origin https://github.com/Isaak-C-Augustus/cool_ahhhhhh_ML_image_learning_effect.git\n",
        "!git push -u origin main\n",
        "\n",
        "https://github.com/MaxRobinsonTheGreat/mandelbrotnn.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing all the necessary Lybraarys and APIs and sheee"
      ],
      "metadata": {
        "id": "MjJ1nl5RwHqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install numpy Pillow scikit_learn torch torchvision tqdm\n",
        "! git clone https://github.com/MaxRobinsonTheGreat/mandelbrotnn.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVTXfXejwAjI",
        "outputId": "4f149d0e-48b3-451e-94ea-f455e0a93118"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit_learn) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "fatal: destination path 'mandelbrotnn' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing the nih as code boahhh"
      ],
      "metadata": {
        "id": "F9Eb0KMFwtlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import src.models as models\n",
        "from src.imageDataset import ImageDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim, nn\n",
        "import matplotlib.pyplot as plt\n",
        "from src.videomaker import renderModel\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Define variables\n",
        "image_path = '/content/drive/MyDrive/MandelBrot/DatasetImages/smiley.png'\n",
        "hidden_size = 300\n",
        "num_hidden_layers = 30\n",
        "batch_size = 8000\n",
        "lr = 0.001\n",
        "num_epochs = 30\n",
        "proj_name = 'smiley_test'\n",
        "save_every_n_iterations = 2\n",
        "scheduler_step = 3\n",
        "\n",
        "# Create the dataset and data loader\n",
        "dataset = ImageDataset(image_path)\n",
        "# dataset.display_image()\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "resx, resy = dataset.width, dataset.height\n",
        "linspace = torch.stack(torch.meshgrid(torch.linspace(-1, 1, resx), torch.linspace(1, -1, resy)), dim=-1).cuda()\n",
        "#rotate the linspace 90 degrees\n",
        "linspace = torch.rot90(linspace, 1, (0, 1))\n",
        "print(linspace.shape)\n",
        "\n",
        "# Create the model\n",
        "# linmap = models.CenteredLinearMap(-1, 1, -1, 1, 2*torch.pi, 2*torch.pi)\n",
        "# model = models.Fourier(32, hidden_size=hidden_size, num_hidden_layers=num_hidden_layers, linmap=linmap).cuda()\n",
        "model = models.SkipConn(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers).cuda()\n",
        "\n",
        "# Create the loss function and optimizer\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=0.5)\n",
        "\n",
        "# Train the model\n",
        "iteration, frame = 0, 0\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    for x, y in tqdm(loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(x).squeeze()\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_func(y_pred, y)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.01)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Save an image of the model every n iterations\n",
        "        if iteration % save_every_n_iterations == 0:\n",
        "            os.makedirs(f'./frames/{proj_name}', exist_ok=True)\n",
        "            plt.imsave(f'./frames/{proj_name}/{frame:05d}.png', renderModel(model, resx=resx, resy=resy, linspace=linspace), cmap='magma', origin='lower')\n",
        "            frame += 1\n",
        "        iteration += 1\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Log the average loss per epoch\n",
        "    print(f'Epoch {epoch+1}, Average Loss: {epoch_loss / len(loader)}')\n",
        "\n",
        "# use ffmpeg to create a video from the frames at the highest quality possible\n",
        "os.system(f'ffmpeg -y -r 30 -i ./frames/{proj_name}/%05d.png -c:v libx264 -preset veryslow -crf 0 -pix_fmt yuv420p ./frames/{proj_name}/{proj_name}.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "M9oGQQGBwsHl",
        "outputId": "de2d5bf4-c0a3-4d74-c831-7371abcba87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ff5504269663>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimageDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push the code to GitHub"
      ],
      "metadata": {
        "id": "E6enkV2zyVrn"
      }
    }
  ]
}